{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from models import shufflenetv2, nasnet_mobile_onfire\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, weight_path, device):\n",
    "    if model_name == \"shufflenetonfire\":\n",
    "        model = shufflenetv2.shufflenet_v2_x0_5(pretrained=False, layers=[4, 8, 4],\n",
    "                                                output_channels=[24, 48, 96, 192, 64], num_classes=1)\n",
    "    elif model_name == \"nasnetonfire\":\n",
    "        model = nasnet_mobile_onfire.nasnetamobile(num_classes=1, pretrained=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Choose 'shufflenetonfire' or 'nasnetonfire'.\")\n",
    "    model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_transform(model_name):\n",
    "    if model_name == 'shufflenetonfire':\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    elif model_name == 'nasnetonfire':\n",
    "        return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "def preprocess_image(image_path, transform, device):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224), cv2.INTER_AREA)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    image = transform(image).float().unsqueeze(0).to(device)\n",
    "    return image\n",
    "\n",
    "def detect_fire(image_path, model, transform, device):\n",
    "    image_tensor = preprocess_image(image_path, transform, device)\n",
    "    output = model(image_tensor)\n",
    "    prediction = torch.round(torch.sigmoid(output)).item()\n",
    "    return \"Fire\" if prediction == 0 else \"No Fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set Parameters ---\n",
    "model_name = \"shufflenetonfire\"            # or \"nasnetonfire\"\n",
    "weight_path = \"weights/shufflenet_ff.pt\"      # adjust path if needed\n",
    "folder_path = \"data/test\"        # update folder path\n",
    "ground_truth = \"Fire\"                      # set to \"Fire\" or \"No Fire\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(model_name, weight_path, device)\n",
    "transform = get_transform(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images tested: 1\n",
      "Correct classifications: 1\n",
      "False Negatives: 0\n",
      "Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "false_count = 0\n",
    "total_images = 0\n",
    "valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "# Iterate over files with a progress bar\n",
    "for filename in tqdm(os.listdir(folder_path), desc=\"Processing images\"):\n",
    "    if filename.lower().endswith(valid_extensions):\n",
    "        total_images += 1\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        result = detect_fire(image_path, model, transform, device)\n",
    "        # Count false positives (for \"No Fire\" ground truth) or false negatives (for \"Fire\")\n",
    "        if (ground_truth == \"No Fire\" and result == \"Fire\") or (ground_truth == \"Fire\" and result == \"No Fire\"):\n",
    "            false_count += 1\n",
    "\n",
    "# Calculate correct classifications and accuracy\n",
    "correct_count = total_images - false_count\n",
    "accuracy = (correct_count / total_images * 100) if total_images > 0 else 0\n",
    "\n",
    "print(f\"Total images tested: {total_images}\")\n",
    "print(f\"Correct classifications: {correct_count}\")\n",
    "if ground_truth == \"No Fire\":\n",
    "    print(f\"False Positives: {false_count}\")\n",
    "else:\n",
    "    print(f\"False Negatives: {false_count}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fire-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
